{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca420e85",
   "metadata": {},
   "source": [
    "# Neural Network Chatbot Setup\n",
    "\n",
    "Notebook ini berisi setup awal untuk membuat chatbot menggunakan neural network dengan NLTK dan TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0e99cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK punkt sudah terinstall\n",
      "Setup berhasil!\n",
      "TensorFlow version: 2.19.0\n",
      "NumPy version: 2.1.3\n",
      "LancasterStemmer telah diinisialisasi\n",
      "Semua library siap digunakan\n"
     ]
    }
   ],
   "source": [
    "# Import semua library yang diperlukan\n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Download 'punkt' dari NLTK dengan pengecekan\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    print(\"NLTK punkt sudah terinstall\")\n",
    "except LookupError:\n",
    "    print(\"Mengunduh NLTK punkt...\")\n",
    "    nltk.download('punkt')\n",
    "    print(\"NLTK punkt berhasil diunduh\")\n",
    "\n",
    "# Inisialisasi LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(\"Setup berhasil!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(\"LancasterStemmer telah diinisialisasi\")\n",
    "print(\"Semua library siap digunakan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3789d845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memproses file intents.json...\n",
      "Jumlah dokumen (patterns): 535\n",
      "Jumlah kelas (intents): 17\n",
      "Jumlah kata unik setelah stemming: 462\n",
      "Kelas yang ditemukan: ['absensi', 'beasiswa', 'cek_nilai', 'goodbye', 'greeting', 'info_dosen', 'jadwal_kuliah', 'jadwal_ujian', 'kontak_admin', 'krs_mata_kuliah', 'pembayaran_spp', 'perpustakaan', 'ruang_kelas', 'skripsi_thesis', 'thanks', 'tugas_pr', 'wifi_internet']\n",
      "Contoh kata setelah stemming: ['a', 'a101', 'abroad', 'abs', 'absens', 'academ', 'account', 'ad', 'admin', 'adv']\n"
     ]
    }
   ],
   "source": [
    "# Memproses file intents.json\n",
    "print(\"Memproses file intents.json...\")\n",
    "\n",
    "# 1. Buka dan muat file 'intents.json'\n",
    "with open('intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 2. Siapkan list kosong untuk 'words', 'classes', dan 'documents'\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "\n",
    "# Kata-kata yang diabaikan (tanda baca dan karakter khusus)\n",
    "ignore_words = ['?', '.', ',', '!', \"'\", '\"', ';', ':', '-', '(', ')', '[', ']', '{', '}']\n",
    "\n",
    "# 3. Lakukan iterasi pada setiap intent di dalam data\n",
    "for intent in data['intents']:\n",
    "    # Untuk setiap pattern dalam intent\n",
    "    for pattern in intent['patterns']:\n",
    "        # 4. Lakukan tokenisasi kata-kata dari pattern\n",
    "        tokens = nltk.word_tokenize(pattern)\n",
    "        \n",
    "        # Masukkan semua token ke dalam list 'words'\n",
    "        words.extend(tokens)\n",
    "        \n",
    "        # Masukkan pasangan (list token, tag) ke dalam list 'documents'\n",
    "        documents.append((tokens, intent['tag']))\n",
    "    \n",
    "    # 5. Kumpulkan semua 'tag' unik ke dalam list 'classes'\n",
    "    if intent['tag'] not in classes:\n",
    "        classes.append(intent['tag'])\n",
    "\n",
    "# 6. Lakukan stemming pada setiap kata di list 'words'\n",
    "# Ubah ke huruf kecil, hapus kata-kata yang diabaikan, dan hapus duplikat\n",
    "words = [stemmer.stem(word.lower()) for word in words if word not in ignore_words]\n",
    "words = list(set(words))  # Hapus duplikat\n",
    "\n",
    "# 7. Urutkan list 'words' dan 'classes'\n",
    "words = sorted(words)\n",
    "classes = sorted(classes)\n",
    "\n",
    "# 8. Cetak jumlah dokumen, kelas, dan kata unik untuk verifikasi\n",
    "print(f\"Jumlah dokumen (patterns): {len(documents)}\")\n",
    "print(f\"Jumlah kelas (intents): {len(classes)}\")\n",
    "print(f\"Jumlah kata unik setelah stemming: {len(words)}\")\n",
    "print(f\"Kelas yang ditemukan: {classes}\")\n",
    "print(f\"Contoh kata setelah stemming: {words[:10]}\")  # Tampilkan 10 kata pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengubah data menjadi format training numerik...\n",
      "Data training berhasil dibuat!\n",
      "Ukuran train_x: (535, 462)\n",
      "Ukuran train_y: (535, 17)\n",
      "Contoh bag of words pertama: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "Contoh output label pertama: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Total training samples: 535\n"
     ]
    }
   ],
   "source": [
    "# Mengubah data menjadi data training numerik\n",
    "print(\"Mengubah data menjadi format training numerik...\")\n",
    "\n",
    "# 1. Buat list 'training' kosong\n",
    "training = []\n",
    "\n",
    "# 2. Buat template output 'output_empty' yang berisi array nol sepanjang jumlah kelas\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# 3. Lakukan iterasi pada list 'documents'\n",
    "for doc in documents:\n",
    "    # a. Buat 'bag of words' (list nol sepanjang jumlah kata unik)\n",
    "    bag = [0] * len(words)\n",
    "    \n",
    "    # Ambil pattern (token) dan tag dari dokumen\n",
    "    pattern_words = doc[0]\n",
    "    tag = doc[1]\n",
    "    \n",
    "    # Stem setiap kata dalam pattern\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    \n",
    "    # b. Untuk setiap kata dalam pattern dokumen, tandai '1' pada posisi yang sesuai di 'bag'\n",
    "    for word in pattern_words:\n",
    "        if word in words:\n",
    "            bag[words.index(word)] = 1\n",
    "    \n",
    "    # c. Buat 'output_row' dengan menyalin 'output_empty' lalu menandai '1' pada posisi tag\n",
    "    output_row = output_empty[:]  # Salin template\n",
    "    output_row[classes.index(tag)] = 1\n",
    "    \n",
    "    # 4. Masukkan pasangan [bag, output_row] ke dalam list 'training'\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# 5. Acak (shuffle) list 'training' dan ubah menjadi NumPy array\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "\n",
    "# 6. Pisahkan array tersebut menjadi 'train_x' (fitur) dan 'train_y' (label)\n",
    "train_x = list(training[:, 0])  # Kolom pertama: bag of words\n",
    "train_y = list(training[:, 1])  # Kolom kedua: output labels\n",
    "\n",
    "# Konversi ke NumPy array dengan tipe float\n",
    "train_x = np.array(train_x, dtype=np.float32)\n",
    "train_y = np.array(train_y, dtype=np.float32)\n",
    "\n",
    "print(\"Data training berhasil dibuat!\")\n",
    "print(f\"Ukuran train_x: {train_x.shape}\")\n",
    "print(f\"Ukuran train_y: {train_y.shape}\")\n",
    "print(f\"Contoh bag of words pertama: {train_x[0]}\")\n",
    "print(f\"Contoh output label pertama: {train_y[0]}\")\n",
    "print(f\"Total training samples: {len(train_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b407f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membangun model Neural Network...\n",
      "Arsitektur model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">59,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,105</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m59,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m)             │         \u001b[38;5;34m1,105\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,625</span> (268.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,625\u001b[0m (268.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,625</span> (268.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,625\u001b[0m (268.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai training model...\n",
      "Epoch 1/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0503 - loss: 2.8400\n",
      "Epoch 2/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1041 - loss: 2.8067\n",
      "Epoch 3/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1420 - loss: 2.7754\n",
      "Epoch 4/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1754 - loss: 2.7350\n",
      "Epoch 5/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1546 - loss: 2.7447\n",
      "Epoch 6/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1384 - loss: 2.7450\n",
      "Epoch 7/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1462 - loss: 2.7370\n",
      "Epoch 8/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1570 - loss: 2.6945\n",
      "Epoch 9/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2221 - loss: 2.6326\n",
      "Epoch 10/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2117 - loss: 2.6274\n",
      "Epoch 11/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2134 - loss: 2.6358\n",
      "Epoch 12/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2293 - loss: 2.5645\n",
      "Epoch 13/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2285 - loss: 2.5625\n",
      "Epoch 14/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2397 - loss: 2.5807\n",
      "Epoch 15/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2582 - loss: 2.5215\n",
      "Epoch 16/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2570 - loss: 2.5096\n",
      "Epoch 17/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2942 - loss: 2.4595\n",
      "Epoch 18/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2934 - loss: 2.4218\n",
      "Epoch 19/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2940 - loss: 2.3957\n",
      "Epoch 20/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3260 - loss: 2.3718\n",
      "Epoch 21/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3040 - loss: 2.3785\n",
      "Epoch 22/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2922 - loss: 2.3664\n",
      "Epoch 23/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3531 - loss: 2.2939\n",
      "Epoch 24/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3439 - loss: 2.2578\n",
      "Epoch 25/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3820 - loss: 2.1572\n",
      "Epoch 26/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3681 - loss: 2.1864\n",
      "Epoch 27/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3744 - loss: 2.2233\n",
      "Epoch 28/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3598 - loss: 2.2177\n",
      "Epoch 29/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3736 - loss: 2.1630\n",
      "Epoch 30/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4184 - loss: 2.0838\n",
      "Epoch 31/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4241 - loss: 2.0513\n",
      "Epoch 32/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4184 - loss: 2.0475\n",
      "Epoch 33/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3996 - loss: 2.1180\n",
      "Epoch 34/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4706 - loss: 1.8945\n",
      "Epoch 35/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4638 - loss: 1.9613\n",
      "Epoch 36/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4081 - loss: 1.9935\n",
      "Epoch 37/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4638 - loss: 1.9111\n",
      "Epoch 38/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4909 - loss: 1.9443\n",
      "Epoch 39/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4537 - loss: 1.8384\n",
      "Epoch 40/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4770 - loss: 1.8264\n",
      "Epoch 41/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4845 - loss: 1.8218\n",
      "Epoch 42/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4768 - loss: 1.8419\n",
      "Epoch 43/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5092 - loss: 1.7563\n",
      "Epoch 44/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5341 - loss: 1.7416\n",
      "Epoch 45/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5385 - loss: 1.6780\n",
      "Epoch 46/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4846 - loss: 1.7057\n",
      "Epoch 47/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5589 - loss: 1.5992\n",
      "Epoch 48/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5283 - loss: 1.6719\n",
      "Epoch 49/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5698 - loss: 1.5644\n",
      "Epoch 50/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5805 - loss: 1.6112\n",
      "Epoch 51/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5915 - loss: 1.5085\n",
      "Epoch 52/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5468 - loss: 1.6228\n",
      "Epoch 53/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5609 - loss: 1.6063\n",
      "Epoch 54/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 1.5309\n",
      "Epoch 55/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5910 - loss: 1.4391\n",
      "Epoch 56/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5845 - loss: 1.4532\n",
      "Epoch 57/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5982 - loss: 1.4395\n",
      "Epoch 58/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 1.4586\n",
      "Epoch 59/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6612 - loss: 1.3757\n",
      "Epoch 60/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6081 - loss: 1.3509\n",
      "Epoch 61/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6355 - loss: 1.3425\n",
      "Epoch 62/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6555 - loss: 1.2863\n",
      "Epoch 63/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6230 - loss: 1.3888\n",
      "Epoch 64/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6411 - loss: 1.3017\n",
      "Epoch 65/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6441 - loss: 1.3407\n",
      "Epoch 66/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 1.1932\n",
      "Epoch 67/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6771 - loss: 1.1846\n",
      "Epoch 68/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6765 - loss: 1.1856\n",
      "Epoch 69/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6899 - loss: 1.1712\n",
      "Epoch 70/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6843 - loss: 1.1794\n",
      "Epoch 71/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 1.1729\n",
      "Epoch 72/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 1.0671\n",
      "Epoch 73/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 1.0758\n",
      "Epoch 74/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7120 - loss: 1.0613\n",
      "Epoch 75/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 1.1290\n",
      "Epoch 76/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7302 - loss: 1.0078\n",
      "Epoch 77/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6857 - loss: 1.0272\n",
      "Epoch 78/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.9387\n",
      "Epoch 79/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.9897\n",
      "Epoch 80/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.9821\n",
      "Epoch 81/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7255 - loss: 0.9351\n",
      "Epoch 82/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7050 - loss: 0.9856\n",
      "Epoch 83/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.8648\n",
      "Epoch 84/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7692 - loss: 0.8563\n",
      "Epoch 85/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7815 - loss: 0.8410\n",
      "Epoch 86/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7718 - loss: 0.8578\n",
      "Epoch 87/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8058 - loss: 0.8434\n",
      "Epoch 88/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7582 - loss: 0.8358\n",
      "Epoch 89/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7990 - loss: 0.7943\n",
      "Epoch 90/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8131 - loss: 0.7503  \n",
      "Epoch 91/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8055 - loss: 0.7190\n",
      "Epoch 92/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.7261\n",
      "Epoch 93/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7982 - loss: 0.7851\n",
      "Epoch 94/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7644 - loss: 0.7757\n",
      "Epoch 95/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8159 - loss: 0.6824\n",
      "Epoch 96/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.6899\n",
      "Epoch 97/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.7027\n",
      "Epoch 98/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.6646\n",
      "Epoch 99/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.6704\n",
      "Epoch 100/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.7197\n",
      "Epoch 101/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.5778\n",
      "Epoch 102/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.6588\n",
      "Epoch 103/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8401 - loss: 0.5455\n",
      "Epoch 104/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.6589\n",
      "Epoch 105/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.6671\n",
      "Epoch 106/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.5818\n",
      "Epoch 107/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.6258\n",
      "Epoch 108/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.5614\n",
      "Epoch 109/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.5758\n",
      "Epoch 110/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8364 - loss: 0.5986\n",
      "Epoch 111/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8360 - loss: 0.5687\n",
      "Epoch 112/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.5130\n",
      "Epoch 113/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.4978\n",
      "Epoch 114/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8846 - loss: 0.5046\n",
      "Epoch 115/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8553 - loss: 0.5437\n",
      "Epoch 116/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.5404\n",
      "Epoch 117/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.4983\n",
      "Epoch 118/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.4854\n",
      "Epoch 119/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.4899\n",
      "Epoch 120/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.4615\n",
      "Epoch 121/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.4859\n",
      "Epoch 122/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.4492\n",
      "Epoch 123/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.4166\n",
      "Epoch 124/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.4522\n",
      "Epoch 125/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.3768\n",
      "Epoch 126/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.4531\n",
      "Epoch 127/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.4260\n",
      "Epoch 128/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.4114\n",
      "Epoch 129/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.4490\n",
      "Epoch 130/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.4588\n",
      "Epoch 131/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.4557\n",
      "Epoch 132/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.4177\n",
      "Epoch 133/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.3971\n",
      "Epoch 134/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.4426\n",
      "Epoch 135/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.3668\n",
      "Epoch 136/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.4448\n",
      "Epoch 137/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.4098\n",
      "Epoch 138/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.3804\n",
      "Epoch 139/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8851 - loss: 0.4011\n",
      "Epoch 140/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.3965\n",
      "Epoch 141/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.3792\n",
      "Epoch 142/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.4269\n",
      "Epoch 143/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.3492\n",
      "Epoch 144/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.3103\n",
      "Epoch 145/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.3940\n",
      "Epoch 146/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.3942\n",
      "Epoch 147/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.3259\n",
      "Epoch 148/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.3605\n",
      "Epoch 149/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.2924\n",
      "Epoch 150/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.3864\n",
      "Epoch 151/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.3523\n",
      "Epoch 152/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.3517\n",
      "Epoch 153/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.3570\n",
      "Epoch 154/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.3551\n",
      "Epoch 155/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2817\n",
      "Epoch 156/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.3267\n",
      "Epoch 157/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.3391\n",
      "Epoch 158/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.2538\n",
      "Epoch 159/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2823\n",
      "Epoch 160/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.3007\n",
      "Epoch 161/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.3483\n",
      "Epoch 162/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.3775\n",
      "Epoch 163/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9430 - loss: 0.2753\n",
      "Epoch 164/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.3788\n",
      "Epoch 165/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.3414\n",
      "Epoch 166/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.2927\n",
      "Epoch 167/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2983\n",
      "Epoch 168/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.2532\n",
      "Epoch 169/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.3382\n",
      "Epoch 170/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2796\n",
      "Epoch 171/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.2416\n",
      "Epoch 172/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.2675\n",
      "Epoch 173/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2520\n",
      "Epoch 174/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.2332\n",
      "Epoch 175/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2842\n",
      "Epoch 176/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.2399\n",
      "Epoch 177/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.2569\n",
      "Epoch 178/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.2872\n",
      "Epoch 179/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.2439\n",
      "Epoch 180/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2665\n",
      "Epoch 181/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.2751\n",
      "Epoch 182/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.2526\n",
      "Epoch 183/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9568 - loss: 0.2240\n",
      "Epoch 184/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.2064\n",
      "Epoch 185/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.2829\n",
      "Epoch 186/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2053\n",
      "Epoch 187/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2280\n",
      "Epoch 188/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.2353\n",
      "Epoch 189/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.2101\n",
      "Epoch 190/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2236\n",
      "Epoch 191/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2518\n",
      "Epoch 192/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2533\n",
      "Epoch 193/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.2438\n",
      "Epoch 194/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2743\n",
      "Epoch 195/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2409\n",
      "Epoch 196/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2318\n",
      "Epoch 197/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.2263\n",
      "Epoch 198/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2863\n",
      "Epoch 199/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2024\n",
      "Epoch 200/200\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.2045\n",
      "\n",
      "Training selesai!\n",
      "Akurasi akhir: 0.9364\n",
      "Loss akhir: 0.2472\n"
     ]
    }
   ],
   "source": [
    "# Membuat dan melatih model Neural Network\n",
    "print(\"Membangun model Neural Network...\")\n",
    "\n",
    "# 1. Buat model Sequential dari Keras\n",
    "model = Sequential()\n",
    "\n",
    "# 2. Tambahkan layer secara berurutan\n",
    "# Dense layer dengan 128 neuron, input_shape sesuai panjang data training, dan aktivasi 'relu'\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "\n",
    "# Dropout layer dengan rate 0.5\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Dense layer dengan 64 neuron dan aktivasi 'relu'\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout layer dengan rate 0.5\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Dense layer dengan jumlah neuron sesuai jumlah kelas dan aktivasi 'softmax'\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "# 3. Compile model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "             optimizer='sgd', \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Tampilkan arsitektur model\n",
    "print(\"Arsitektur model:\")\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nMemulai training model...\")\n",
    "\n",
    "# 4. Latih model (model.fit) selama 200 epoch dengan batch_size 5\n",
    "history = model.fit(train_x, train_y, \n",
    "                   epochs=200, \n",
    "                   batch_size=5, \n",
    "                   verbose=1)\n",
    "\n",
    "print(\"\\nTraining selesai!\")\n",
    "print(f\"Akurasi akhir: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Loss akhir: {history.history['loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53fd9c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menyimpan model dan data...\n",
      "✓ Model berhasil disimpan ke 'chatbot_model.h5'\n",
      "✓ Data words dan classes berhasil disimpan ke 'data.pickle'\n",
      "\n",
      "🎉 Proses training dan penyimpanan selesai!\n",
      "File yang telah dibuat:\n",
      "- chatbot_model.h5 (Model neural network)\n",
      "- data.pickle (Vocabulary dan classes)\n",
      "\n",
      "Model chatbot siap digunakan!\n"
     ]
    }
   ],
   "source": [
    "# Menyimpan model dan data yang sudah dilatih\n",
    "print(\"Menyimpan model dan data...\")\n",
    "\n",
    "# Simpan model yang sudah dilatih ke file 'chatbot_model.h5'\n",
    "model.save('chatbot_model.h5')\n",
    "print(\"✓ Model berhasil disimpan ke 'chatbot_model.h5'\")\n",
    "\n",
    "# Simpan list 'words' dan 'classes' ke dalam file 'data.pickle' menggunakan pickle\n",
    "with open('data.pickle', 'wb') as file:\n",
    "    pickle.dump({'words': words, 'classes': classes}, file)\n",
    "print(\"✓ Data words dan classes berhasil disimpan ke 'data.pickle'\")\n",
    "\n",
    "print(\"\\n🎉 Proses training dan penyimpanan selesai!\")\n",
    "print(\"File yang telah dibuat:\")\n",
    "print(\"- chatbot_model.h5 (Model neural network)\")\n",
    "print(\"- data.pickle (Vocabulary dan classes)\")\n",
    "print(\"\\nModel chatbot siap digunakan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e5a23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat fungsi-fungsi untuk prediksi...\n",
      "✓ Fungsi prediksi berhasil dibuat:\n",
      "- clean_up_sentence(): tokenisasi dan stemming\n",
      "- bow(): konversi ke bag-of-words\n",
      "- predict_class(): prediksi intent dengan model\n",
      "- getResponse(): pemilihan respons acak\n",
      "\n",
      "Fungsi-fungsi siap digunakan untuk chatbot!\n"
     ]
    }
   ],
   "source": [
    "# Fungsi-fungsi untuk prediksi dan respons chatbot\n",
    "print(\"Membuat fungsi-fungsi untuk prediksi...\")\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan tokenisasi dan stemming pada kalimat input\n",
    "    \"\"\"\n",
    "    # Tokenisasi kalimat\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # Stemming setiap kata dan ubah ke huruf kecil\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    \n",
    "    return sentence_words\n",
    "\n",
    "def bow(sentence, words):\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengubah kalimat menjadi bag-of-words berdasarkan vocabulary\n",
    "    \"\"\"\n",
    "    # Bersihkan kalimat input\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    \n",
    "    # Buat bag dengan panjang sesuai vocabulary\n",
    "    bag = [0] * len(words)\n",
    "    \n",
    "    # Tandai 1 untuk kata yang ada dalam vocabulary\n",
    "    for s in sentence_words:\n",
    "        for i, word in enumerate(words):\n",
    "            if word == s:\n",
    "                bag[i] = 1\n",
    "    \n",
    "    # Konversi ke numpy array\n",
    "    return np.array(bag, dtype=np.float32)\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memprediksi intent dari kalimat menggunakan model\n",
    "    \"\"\"\n",
    "    # Buat bag of words dari kalimat\n",
    "    p = bow(sentence, words)\n",
    "    \n",
    "    # Reshape untuk input model (batch dimension)\n",
    "    p = p.reshape(1, -1)\n",
    "    \n",
    "    # Prediksi menggunakan model\n",
    "    res = model.predict(p)[0]\n",
    "    \n",
    "    # Threshold probabilitas minimum\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    \n",
    "    # Filter hasil prediksi di atas threshold\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    \n",
    "    # Urutkan berdasarkan probabilitas (tertinggi dulu)\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Buat list intent dengan probabilitas\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memilih respons acak dari intent dengan probabilitas tertinggi\n",
    "    \"\"\"\n",
    "    if len(ints) == 0:\n",
    "        return \"Maaf, saya tidak mengerti. Bisakah Anda mengulanginya?\"\n",
    "    \n",
    "    # Ambil tag intent dengan probabilitas tertinggi\n",
    "    tag = ints[0]['intent']\n",
    "    \n",
    "    # Cari intent dalam data JSON\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if i['tag'] == tag:\n",
    "            # Pilih respons secara acak dari list responses\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    else:\n",
    "        result = \"Maaf, saya tidak dapat memberikan respons untuk pertanyaan tersebut.\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"✓ Fungsi prediksi berhasil dibuat:\")\n",
    "print(\"- clean_up_sentence(): tokenisasi dan stemming\")\n",
    "print(\"- bow(): konversi ke bag-of-words\")\n",
    "print(\"- predict_class(): prediksi intent dengan model\")\n",
    "print(\"- getResponse(): pemilihan respons acak\")\n",
    "print(\"\\nFungsi-fungsi siap digunakan untuk chatbot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49bfa97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat model dan data untuk chatbot...\n",
      "✓ Model berhasil dimuat dari 'chatbot_model.h5'\n",
      "✓ Data words dan classes berhasil dimuat dari 'data.pickle'\n",
      "✓ Data intents berhasil dimuat dari 'intents.json'\n",
      "\n",
      "🤖 Chatbot Neural Network siap digunakan!\n",
      "PENTING: Untuk menghentikan chatbot, ketik 'quit' atau 'exit'\n",
      "Atau gunakan Kernel > Interrupt untuk menghentikan paksa\n",
      "==================================================\n",
      "Memulai chatbot... (Tekan Ctrl+C atau ketik 'quit' untuk berhenti)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Bot: Yooo! Gimana kuliahnya? Ada yang perlu ditanyain?\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Bot: Yooo! Gimana kuliahnya? Ada yang perlu ditanyain?\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Bot: Halo kak! Ada pertanyaan tentang jadwal, nilai, atau yang lain?\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Bot: Halo kak! Ada pertanyaan tentang jadwal, nilai, atau yang lain?\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Bot: Nilai bisa dicek di portal akademik dengan login NIM. Biasanya keluar 1-2 minggu setelah ujian.\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Bot: Nilai bisa dicek di portal akademik dengan login NIM. Biasanya keluar 1-2 minggu setelah ujian.\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Bot: Jadwal kuliah real-time ada di aplikasi kampus. Pastikan sudah login ya!\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Bot: Jadwal kuliah real-time ada di aplikasi kampus. Pastikan sudah login ya!\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Bot: Sama-sama! Semoga informasinya membantu ya ðŸ˜Š\n",
      "------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Bot: Sama-sama! Semoga informasinya membantu ya ðŸ˜Š\n",
      "------------------------------\n",
      "Bot: Terima kasih telah menggunakan chatbot! Sampai jumpa! 👋\n",
      "Bot: Terima kasih telah menggunakan chatbot! Sampai jumpa! 👋\n"
     ]
    }
   ],
   "source": [
    "# Menjalankan chatbot secara interaktif\n",
    "print(\"Memuat model dan data untuk chatbot...\")\n",
    "\n",
    "# 1. Muat kembali model dari file 'chatbot_model.h5'\n",
    "from tensorflow.keras.models import load_model\n",
    "chatbot_model = load_model('chatbot_model.h5')\n",
    "print(\"✓ Model berhasil dimuat dari 'chatbot_model.h5'\")\n",
    "\n",
    "# 2. Muat kembali 'words' dan 'classes' dari file 'data.pickle'\n",
    "with open('data.pickle', 'rb') as file:\n",
    "    data_loaded = pickle.load(file)\n",
    "    words_loaded = data_loaded['words']\n",
    "    classes_loaded = data_loaded['classes']\n",
    "print(\"✓ Data words dan classes berhasil dimuat dari 'data.pickle'\")\n",
    "\n",
    "# 3. Muat kembali data dari 'intents.json'\n",
    "with open('intents.json') as file:\n",
    "    intents_data = json.load(file)\n",
    "print(\"✓ Data intents berhasil dimuat dari 'intents.json'\")\n",
    "\n",
    "# 4. Buat fungsi 'chatbot_response(text)' yang mengoordinasikan prediksi dan respons\n",
    "def chatbot_response(text):\n",
    "    \"\"\"\n",
    "    Fungsi untuk mendapatkan respons chatbot dari input text\n",
    "    \"\"\"\n",
    "    # Prediksi intent dari input text\n",
    "    ints = predict_class(text, chatbot_model)\n",
    "    \n",
    "    # Dapatkan respons berdasarkan intent yang diprediksi\n",
    "    response = getResponse(ints, intents_data)\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"\\n🤖 Chatbot Neural Network siap digunakan!\")\n",
    "print(\"PENTING: Untuk menghentikan chatbot, ketik 'quit' atau 'exit'\")\n",
    "print(\"Atau gunakan Kernel > Interrupt untuk menghentikan paksa\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 5. Fungsi untuk menjalankan chatbot dengan handling error yang lebih baik\n",
    "def run_chatbot():\n",
    "    try:\n",
    "        while True:\n",
    "            # Meminta input dari pengguna\n",
    "            user_input = input(\"Anda: \")\n",
    "            \n",
    "            # 6. Jika pengguna mengetik 'quit' atau 'exit', hentikan loop\n",
    "            if user_input.lower() in ['quit', 'exit', 'stop', 'keluar']:\n",
    "                print(\"Bot: Terima kasih telah menggunakan chatbot! Sampai jumpa! 👋\")\n",
    "                break\n",
    "            \n",
    "            # Skip jika input kosong\n",
    "            if not user_input.strip():\n",
    "                continue\n",
    "            \n",
    "            # 7. Untuk setiap input, panggil fungsi 'chatbot_response' dan cetak balasan\n",
    "            bot_response = chatbot_response(user_input)\n",
    "            print(f\"Bot: {bot_response}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nBot: Chatbot dihentikan oleh pengguna. Sampai jumpa! 👋\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nTerjadi error: {e}\")\n",
    "        print(\"Chatbot dihentikan.\")\n",
    "\n",
    "# Jalankan chatbot\n",
    "print(\"Memulai chatbot... (Tekan Ctrl+C atau ketik 'quit' untuk berhenti)\")\n",
    "run_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a232fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
